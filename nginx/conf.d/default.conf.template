server {
    listen 80;
    server_name _;
    
    # Global settings
    client_max_body_size 10M;
    
    # Global authentication
    auth_basic "LM Studio API Access";
    auth_basic_user_file /etc/nginx/.htpasswd;

    # LM Studio OpenAI-compatible endpoints
    location /v1/ {
        proxy_pass http://host.docker.internal:1234;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_connect_timeout 90s;
        proxy_send_timeout 330s;
        proxy_read_timeout 330s;
        proxy_buffering off;
        proxy_request_buffering off;
    }

    # Health check
    location /health {
        return 200 '{"status":"ok"}';
        add_header Content-Type application/json;
    }

    # Catch-all for other paths
    location / {
        return 404 '{"error":"Not found"}';
        add_header Content-Type application/json;
    }
}

