server {
    listen 80;
    server_name _;
    
    # Basic settings
    client_max_body_size 100M;
    
    # Global authentication
    auth_basic "LM Studio API Access";
    auth_basic_user_file /etc/nginx/.htpasswd;

    # LM Studio OpenAI-compatible endpoints
    location /v1/ {
        proxy_pass http://host.docker.internal:1234;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_connect_timeout 120s;
        proxy_send_timeout 900s;
        proxy_read_timeout 900s;
        proxy_buffering off;
        proxy_request_buffering off;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
    }

    # Health check
    location /health {
        return 200 '{"status":"ok"}';
        add_header Content-Type application/json;
    }

    # All other LM Studio endpoints
    location / {
        proxy_pass http://host.docker.internal:1234;
        proxy_set_header Host $host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_connect_timeout 120s;
        proxy_send_timeout 900s;
        proxy_read_timeout 900s;
        proxy_buffering off;
        proxy_request_buffering off;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
    }
}

